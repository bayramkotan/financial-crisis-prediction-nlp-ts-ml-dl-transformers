{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b01CXRVi4Qi"
      },
      "source": [
        "# 5. BIST50 Çoklu Hisse Derin Öğrenme Analizi\n",
        "\n",
        "**Amaç:** RNN, LSTM, CNN, MLP modellerini 50 hisse ile eğitmek\n",
        "\n",
        "**Hipotez:** Veri miktarı artınca (250 → 12,500 sample), derin öğrenme modelleri çok daha iyi performans gösterecek\n",
        "\n",
        "**Karşılaştırma:**\n",
        "- 1_bist50_DL.ipynb → 1 hisse, 250 sample\n",
        "- 5_bist50_full_DL.ipynb → 50 hisse, 12,500 sample (44x daha fazla!)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siC8Aif4i4Qk"
      },
      "source": [
        "## 1. Kurulum ve Ortam Ayarları"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eARU15b9i4Ql",
        "outputId": "6fb75a4d-6975-41e5-8a1f-acd3491064ec",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705252432,
          "user_tz": -180,
          "elapsed": 19926,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        }
      },
      "outputs": [],
      "source": [
        "# Google Drive'ı mount et\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "# Veri ve sonuçlar klasörlerini ayarla\n",
        "DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/tez/Data/BIST_50_2018_Data_Full_Imputed.csv'\n",
        "RESULTS_DIR = '/content/drive/MyDrive/Colab Notebooks/Sonuclar/5_DeepLearning_Full'\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\" Drive mounted\")\n",
        "print(f\" Veri dosyası: {DATA_PATH}\")\n",
        "print(f\" Sonuçlar klasörü: {RESULTS_DIR}\")\n",
        "\n",
        "# Dosya varlık kontrolü\n",
        "if not os.path.exists(DATA_PATH):\n",
        " print(f\"\\n HATA: Veri dosyası bulunamadı!\")\n",
        " print(f\" Lütfen BIST_50_2018_Data_Full_Imputed.csv dosyasını .../tez/Data/ klasörüne kopyalayın\")\n",
        " raise FileNotFoundError(DATA_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8ST29hgi4Qm",
        "outputId": "50f05b0a-b3bc-4486-9934-9700ee9e5900",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705262618,
          "user_tz": -180,
          "elapsed": 10182,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        }
      },
      "outputs": [],
      "source": [
        "# Temel kütüphaneler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Deep Learning - TensorFlow/Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, SimpleRNN, Conv1D, MaxPooling1D, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "print(\" Kütüphaneler yüklendi\")\n",
        "print(f\" TensorFlow version: {tf.__version__}\")\n",
        "print(f\" NumPy version: {np.__version__}\")\n",
        "print(f\" Pandas version: {pd.__version__}\")\n",
        "\n",
        "# GPU kontrolü\n",
        "print(f\"\\n GPU Durumu:\")\n",
        "print(f\" GPU mevcut mu: {tf.test.is_gpu_available()}\")\n",
        "print(f\" GPU cihazları: {tf.config.list_physical_devices('GPU')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C6uC3Xki4Qm"
      },
      "source": [
        "## 2. Veri Setinin Yüklenmesi ve Ön İşleme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "VOz38Fpqi4Qn",
        "outputId": "f7b05f14-b582-44a0-cf1d-abf94cf953c1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705263855,
          "user_tz": -180,
          "elapsed": 1235,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        }
      },
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\" VERİ YÜKLEME\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# CSV'yi oku\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "print(f\" Veri yüklendi!\")\n",
        "print(f\" Toplam Satır: {len(df):,}\")\n",
        "print(f\" Toplam Sütun: {len(df.columns):,}\")\n",
        "\n",
        "# Tarihi düzelt\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%d.%m.%Y')\n",
        "\n",
        "# Hisse listesini çıkar\n",
        "all_columns = df.columns.tolist()\n",
        "stock_tickers = []\n",
        "for col in all_columns:\n",
        "    if col != 'Date' and '_Now' in col:\n",
        "        ticker = col.replace('_Now', '')\n",
        "        stock_tickers.append(ticker)\n",
        "\n",
        "print(f\"\\nToplam Hisse: {len(stock_tickers)}\")\n",
        "print(f\"İlk 10 Hisse: {stock_tickers[:10]}\")\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06ICwO89i4Qn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01585987-50dd-48e0-a3fe-e44ca73df4fd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705263948,
          "user_tz": -180,
          "elapsed": 66,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        }
      },
      "outputs": [],
      "source": [
        "def parse_turkish_number(value):\n",
        "    \"\"\"Türk formatındaki sayıyı float'a çevir (1.234,56 → 1234.56)\"\"\"\n",
        "    if pd.isna(value) or value == '' or value is None:\n",
        "        return np.nan\n",
        "\n",
        "    try:\n",
        "        value = str(value).strip()\n",
        "\n",
        "        if not value or value == 'nan':\n",
        "            return np.nan\n",
        "\n",
        "        # M ve B için\n",
        "        if 'M' in value:\n",
        "            value = value.replace('M', '').replace(',', '.').strip()\n",
        "            return float(value) * 1_000_000\n",
        "        elif 'B' in value:\n",
        "            value = value.replace('B', '').replace(',', '.').strip()\n",
        "            return float(value) * 1_000_000_000\n",
        "\n",
        "        # Normal sayı: 1.234,56 → 1234.56\n",
        "        value = value.replace('.', '')  # Binlik ayracı\n",
        "        value = value.replace(',', '.')  # Ondalık ayracı\n",
        "        value = value.replace('%', '')  # Yüzde\n",
        "\n",
        "        return float(value)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "# Tüm sayısal kolonları dönüştür\n",
        "print(\" Sayısal veriler dönüştürülüyor...\")\n",
        "\n",
        "for ticker in stock_tickers:\n",
        "    for col_type in ['Now', 'Open', 'High', 'Low', 'Volume']:\n",
        "        col_name = f'{ticker}_{col_type}'\n",
        "        if col_name in df.columns:\n",
        "            df[col_name] = df[col_name].apply(parse_turkish_number)\n",
        "\n",
        "    diff_col = f'{ticker}_Diff%'\n",
        "    if diff_col in df.columns:\n",
        "        df[diff_col] = df[diff_col].apply(parse_turkish_number)\n",
        "\n",
        "print(\" Veri dönüştürme tamamlandı\")\n",
        "print(f\"\\n Örnek Veri (AKBNK):\")\n",
        "print(df[['Date', 'AKBNK_Now', 'AKBNK_Open', 'AKBNK_Volume']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7sfPNx1i4Qn"
      },
      "source": [
        "## 3. Çoklu Hisse Veri Seti Oluşturma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0jHP5Bdi4Qo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "88b7095a-49ce-46d4-8654-6c38bc071dd2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705264918,
          "user_tz": -180,
          "elapsed": 952,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        }
      },
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\" MULTI-STOCK DATASET OLUŞTURMA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Long format'a dönüştür\n",
        "data_list = []\n",
        "\n",
        "for ticker in stock_tickers:\n",
        " for idx, row in df.iterrows():\n",
        "     data_list.append({\n",
        " 'Date': row['Date'],\n",
        " 'Ticker': ticker,\n",
        " 'Now': row[f'{ticker}_Now'],\n",
        " 'Open': row[f'{ticker}_Open'],\n",
        " 'High': row[f'{ticker}_High'],\n",
        " 'Low': row[f'{ticker}_Low'],\n",
        " 'Volume': row[f'{ticker}_Volume'],\n",
        " 'Diff_pct': row[f'{ticker}_Diff%']\n",
        " })\n",
        "\n",
        "df_long = pd.DataFrame(data_list)\n",
        "\n",
        "print(f\" Long format oluşturuldu!\")\n",
        "print(f\" Toplam satır: {len(df_long):,}\")\n",
        "print(f\" 50 hisse × {len(df)} gün = {len(df_long):,} sample\")\n",
        "\n",
        "# NaN kontrolü\n",
        "print(f\"\\n NaN değer sayısı:\")\n",
        "print(df_long.isna().sum())\n",
        "\n",
        "# NaN'ları temizle\n",
        "df_long = df_long.dropna()\n",
        "print(f\"\\n Temizleme sonrası: {len(df_long):,} sample\")\n",
        "\n",
        "df_long.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AaXYtJSi4Qo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "73097936-6eea-4599-9f3c-fe20c5ebf666",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705265275,
          "user_tz": -180,
          "elapsed": 354,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        }
      },
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\" TEKNİK GÖSTERGELER EKLEME\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Hisse bazında grupla ve sırala\n",
        "df_long = df_long.sort_values(['Ticker', 'Date']).reset_index(drop=True)\n",
        "\n",
        "# Her hisse için teknik göstergeler hesapla\n",
        "features_list = []\n",
        "\n",
        "for ticker in df_long['Ticker'].unique():\n",
        " ticker_data = df_long[df_long['Ticker'] == ticker].copy()\n",
        "\n",
        " # Returns\n",
        " ticker_data['Return_1d'] = ticker_data['Now'].pct_change(1)\n",
        " ticker_data['Return_5d'] = ticker_data['Now'].pct_change(5)\n",
        "\n",
        " # Moving Averages\n",
        " ticker_data['MA_5'] = ticker_data['Now'].rolling(window=5).mean()\n",
        " ticker_data['MA_20'] = ticker_data['Now'].rolling(window=20).mean()\n",
        "\n",
        " # Volatility\n",
        " ticker_data['Vol_5d'] = ticker_data['Return_1d'].rolling(window=5).std()\n",
        "\n",
        " # RSI (14-period)\n",
        " delta = ticker_data['Now'].diff()\n",
        " gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
        " loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
        " rs = gain / loss\n",
        " ticker_data['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        " # Target: Next day price\n",
        " ticker_data['Target'] = ticker_data['Now'].shift(-1)\n",
        "\n",
        " features_list.append(ticker_data)\n",
        "\n",
        "# Birleştir\n",
        "df_features = pd.concat(features_list, ignore_index=True)\n",
        "\n",
        "# NaN temizle\n",
        "df_features = df_features.dropna()\n",
        "\n",
        "print(f\" Teknik göstergeler eklendi!\")\n",
        "print(f\" Final dataset: {len(df_features):,} sample\")\n",
        "print(f\" Özellik sayısı: {len(df_features.columns)}\")\n",
        "print(f\"\\n Kolonlar:\")\n",
        "print(df_features.columns.tolist())\n",
        "\n",
        "df_features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ite8ZwMSi4Qp"
      },
      "source": [
        "## 4. Eğitim ve Test Verilerinin Ayrılması"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "855oBDAWi4Qp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b06cec22-7135-4172-f1c2-5fdcd8d314ec",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705265303,
          "user_tz": -180,
          "elapsed": 24,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        }
      },
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\" TRAIN/TEST SPLIT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Time-based split (son 21 gün = test)\n",
        "df_features = df_features.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "# Her hisse için aynı split\n",
        "unique_dates = sorted(df_features['Date'].unique())\n",
        "split_date = unique_dates[-21] # Son 21 gün test\n",
        "\n",
        "train_df = df_features[df_features['Date'] < split_date].copy()\n",
        "test_df = df_features[df_features['Date'] >= split_date].copy()\n",
        "\n",
        "print(f\"Split Date: {split_date.strftime('%Y-%m-%d')}\")\n",
        "print(f\"\\nTrain Set:\")\n",
        "print(f\" Satır: {len(train_df):,}\")\n",
        "print(f\" Tarih aralığı: {train_df['Date'].min()} - {train_df['Date'].max()}\")\n",
        "\n",
        "print(f\"\\nTest Set:\")\n",
        "print(f\" Satır: {len(test_df):,}\")\n",
        "print(f\" Tarih aralığı: {test_df['Date'].min()} - {test_df['Date'].max()}\")\n",
        "\n",
        "# Feature columns\n",
        "feature_cols = ['Open', 'High', 'Low', 'Volume', 'Return_1d', 'Return_5d',\n",
        " 'MA_5', 'MA_20', 'Vol_5d', 'RSI']\n",
        "\n",
        "print(f\"\\n Kullanılan özellikler ({len(feature_cols)} adet):\")\n",
        "for i, col in enumerate(feature_cols, 1):\n",
        " print(f\" {i}. {col}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXTDkWPmi4Qq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47bf922d-a80f-4f00-d8ab-dedc0fa17348",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705266072,
          "user_tz": -180,
          "elapsed": 766,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        }
      },
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\" DATA SCALING (HİSSE BAZLI NORMALİZASYON)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Her hisse için ayrı scaler saklayacağız\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scalers_X = {}  # Her hisse için feature scaler\n",
        "scalers_y = {}  # Her hisse için target scaler\n",
        "\n",
        "# Train ve test dataframe'lerine scaled değerler için yeni sütunlar\n",
        "train_df_scaled = train_df.copy()\n",
        "test_df_scaled = test_df.copy()\n",
        "\n",
        "# Feature sütunları için scaled versiyonlar\n",
        "scaled_feature_cols = [f\"{col}_scaled\" for col in feature_cols]\n",
        "\n",
        "print(\" Hisse bazlı normalizasyon yapılıyor...\")\n",
        "\n",
        "# Her hisse için ayrı normalizasyon\n",
        "for ticker in train_df['Ticker'].unique():\n",
        "    # Train ve test mask\n",
        "    train_mask = train_df['Ticker'] == ticker\n",
        "    test_mask = test_df['Ticker'] == ticker\n",
        "\n",
        "    # Feature scaler - train üzerinde fit\n",
        "    scalers_X[ticker] = StandardScaler()\n",
        "    train_scaled_features = scalers_X[ticker].fit_transform(\n",
        "        train_df.loc[train_mask, feature_cols]\n",
        "    )\n",
        "    train_df_scaled.loc[train_mask, scaled_feature_cols] = train_scaled_features\n",
        "\n",
        "    # Test varsa transform\n",
        "    if test_mask.sum() > 0:\n",
        "        test_scaled_features = scalers_X[ticker].transform(\n",
        "            test_df.loc[test_mask, feature_cols]\n",
        "        )\n",
        "        test_df_scaled.loc[test_mask, scaled_feature_cols] = test_scaled_features\n",
        "\n",
        "    # Target scaler - train üzerinde fit\n",
        "    scalers_y[ticker] = StandardScaler()\n",
        "    train_scaled_target = scalers_y[ticker].fit_transform(\n",
        "        train_df.loc[train_mask, ['Target']]\n",
        "    )\n",
        "    train_df_scaled.loc[train_mask, 'Target_scaled'] = train_scaled_target.flatten()\n",
        "\n",
        "    # Test varsa transform\n",
        "    if test_mask.sum() > 0:\n",
        "        test_scaled_target = scalers_y[ticker].transform(\n",
        "            test_df.loc[test_mask, ['Target']]\n",
        "        )\n",
        "        test_df_scaled.loc[test_mask, 'Target_scaled'] = test_scaled_target.flatten()\n",
        "\n",
        "print(f\" {len(scalers_X)} hisse için ayrı scaler oluşturuldu!\")\n",
        "\n",
        "# Numpy array'e çevir (scaled değerler)\n",
        "X_train = train_df_scaled[scaled_feature_cols].values\n",
        "X_test = test_df_scaled[scaled_feature_cols].values\n",
        "y_train = train_df_scaled[['Target_scaled']].values\n",
        "y_test = test_df_scaled[['Target_scaled']].values\n",
        "\n",
        "# Ticker bilgisini sakla (denormalizasyon için)\n",
        "train_tickers = train_df['Ticker'].values\n",
        "test_tickers = test_df['Ticker'].values\n",
        "\n",
        "print(f\"\\nX_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "# Sequence oluşturma (RNN/LSTM/CNN için)\n",
        "# DİKKAT: Hisse sınırlarını geçmemeli!\n",
        "def create_sequences_by_ticker(df_scaled, feature_cols, time_steps=5):\n",
        "    \"\"\"Her hisse için ayrı sequence oluştur, sonra birleştir\"\"\"\n",
        "    all_X, all_y, all_tickers = [], [], []\n",
        "\n",
        "    for ticker in df_scaled['Ticker'].unique():\n",
        "        ticker_data = df_scaled[df_scaled['Ticker'] == ticker].sort_values('Date')\n",
        "        X_ticker = ticker_data[feature_cols].values\n",
        "        y_ticker = ticker_data['Target_scaled'].values\n",
        "\n",
        "        for i in range(len(X_ticker) - time_steps):\n",
        "            all_X.append(X_ticker[i:(i + time_steps)])\n",
        "            all_y.append(y_ticker[i + time_steps])\n",
        "            all_tickers.append(ticker)\n",
        "\n",
        "    return np.array(all_X), np.array(all_y).reshape(-1, 1), all_tickers\n",
        "\n",
        "# 5 günlük sequence oluştur\n",
        "TIME_STEPS = 5\n",
        "X_train_seq, y_train_seq, train_seq_tickers = create_sequences_by_ticker(\n",
        "    train_df_scaled, scaled_feature_cols, TIME_STEPS\n",
        ")\n",
        "X_test_seq, y_test_seq, test_seq_tickers = create_sequences_by_ticker(\n",
        "    test_df_scaled, scaled_feature_cols, TIME_STEPS\n",
        ")\n",
        "\n",
        "print(f\"\\n Sequence shapes:\")\n",
        "print(f\"X_train_seq: {X_train_seq.shape} # (samples, time_steps, features)\")\n",
        "print(f\"y_train_seq: {y_train_seq.shape}\")\n",
        "print(f\"X_test_seq: {X_test_seq.shape}\")\n",
        "print(f\"y_test_seq: {y_test_seq.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kBu3X3ri4Qr"
      },
      "source": [
        "## 5. Derin Öğrenme Modelleri"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvoo8fKKi4Qr"
      },
      "source": [
        "### 5.1. RNN (Tekrarlayan Sinir Ağı)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DllkL27i4Qr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1d982b3-039f-45e8-bb2f-d37b93010324",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705293477,
          "user_tz": -180,
          "elapsed": 27374,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        }
      },
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\" RNN MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Model oluştur\n",
        "model_rnn = Sequential([\n",
        " SimpleRNN(64, activation='tanh', return_sequences=True,\n",
        " input_shape=(TIME_STEPS, X_train.shape[1])),\n",
        " Dropout(0.2),\n",
        " SimpleRNN(32, activation='tanh'),\n",
        " Dropout(0.2),\n",
        " Dense(16, activation='relu'),\n",
        " Dense(1)\n",
        "])\n",
        "\n",
        "model_rnn.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "\n",
        "print(\" RNN modeli oluşturuldu!\")\n",
        "model_rnn.summary()\n",
        "\n",
        "# Eğit\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "print(\"\\n RNN eğitiliyor...\")\n",
        "history_rnn = model_rnn.fit(\n",
        " X_train_seq, y_train_seq,\n",
        " validation_split=0.2,\n",
        " epochs=100,\n",
        " batch_size=32,\n",
        " callbacks=[early_stop],\n",
        " verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n RNN eğitim tamamlandı!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTq71osRi4Qs"
      },
      "source": [
        "### 5.2. LSTM (Uzun Kısa Vadeli Bellek)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ye6CvIpi4Qs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "95b5ab5b-d933-40f5-b8d9-8dc58fb52a72",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705337104,
          "user_tz": -180,
          "elapsed": 43618,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        }
      },
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\" LSTM MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Model oluştur\n",
        "model_lstm = Sequential([\n",
        " LSTM(64, activation='tanh', return_sequences=True,\n",
        " input_shape=(TIME_STEPS, X_train.shape[1])),\n",
        " Dropout(0.2),\n",
        " LSTM(32, activation='tanh'),\n",
        " Dropout(0.2),\n",
        " Dense(16, activation='relu'),\n",
        " Dense(1)\n",
        "])\n",
        "\n",
        "model_lstm.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "\n",
        "print(\" LSTM modeli oluşturuldu!\")\n",
        "model_lstm.summary()\n",
        "\n",
        "# Eğit\n",
        "print(\"\\n LSTM eğitiliyor...\")\n",
        "history_lstm = model_lstm.fit(\n",
        " X_train_seq, y_train_seq,\n",
        " validation_split=0.2,\n",
        " epochs=100,\n",
        " batch_size=32,\n",
        " callbacks=[early_stop],\n",
        " verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n LSTM eğitim tamamlandı!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgcbIKyki4Qs"
      },
      "source": [
        "### 5.3. CNN (Evrişimli Sinir Ağı)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QF6f-Kv2i4Qs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "95a9a64c-49c5-4323-8642-56488ebafee7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705352830,
          "user_tz": -180,
          "elapsed": 15715,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        }
      },
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\" CNN MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Model oluştur\n",
        "model_cnn = Sequential([\n",
        " Conv1D(filters=64, kernel_size=2, activation='relu',\n",
        " input_shape=(TIME_STEPS, X_train.shape[1])),\n",
        " MaxPooling1D(pool_size=2),\n",
        " Dropout(0.2),\n",
        " Conv1D(filters=32, kernel_size=2, activation='relu'),\n",
        " Dropout(0.2),\n",
        " Flatten(),\n",
        " Dense(16, activation='relu'),\n",
        " Dense(1)\n",
        "])\n",
        "\n",
        "model_cnn.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "\n",
        "print(\" CNN modeli oluşturuldu!\")\n",
        "model_cnn.summary()\n",
        "\n",
        "# Eğit\n",
        "print(\"\\n CNN eğitiliyor...\")\n",
        "history_cnn = model_cnn.fit(\n",
        " X_train_seq, y_train_seq,\n",
        " validation_split=0.2,\n",
        " epochs=100,\n",
        " batch_size=32,\n",
        " callbacks=[early_stop],\n",
        " verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n CNN eğitim tamamlandı!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yJWQ_Vzi4Qt"
      },
      "source": [
        "### 5.4. MLP (Çok Katmanlı Algılayıcı)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZ9eM4Ipi4Qt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "644b8c6a-4215-424c-fc26-44fbdc934f8e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705385039,
          "user_tz": -180,
          "elapsed": 32196,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        }
      },
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\" MLP MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# MLP için sequence yerine flat kullan\n",
        "# Flatten the sequences\n",
        "X_train_mlp = X_train_seq.reshape(X_train_seq.shape[0], -1)\n",
        "X_test_mlp = X_test_seq.reshape(X_test_seq.shape[0], -1)\n",
        "\n",
        "print(f\"MLP Input shape: {X_train_mlp.shape}\")\n",
        "\n",
        "# Model oluştur\n",
        "model_mlp = Sequential([\n",
        " Dense(128, activation='relu', input_shape=(X_train_mlp.shape[1],)),\n",
        " Dropout(0.3),\n",
        " Dense(64, activation='relu'),\n",
        " Dropout(0.3),\n",
        " Dense(32, activation='relu'),\n",
        " Dropout(0.2),\n",
        " Dense(16, activation='relu'),\n",
        " Dense(1)\n",
        "])\n",
        "\n",
        "model_mlp.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "\n",
        "print(\"\\n MLP modeli oluşturuldu!\")\n",
        "model_mlp.summary()\n",
        "\n",
        "# Eğit\n",
        "print(\"\\n MLP eğitiliyor...\")\n",
        "history_mlp = model_mlp.fit(\n",
        " X_train_mlp, y_train_seq,\n",
        " validation_split=0.2,\n",
        " epochs=100,\n",
        " batch_size=32,\n",
        " callbacks=[early_stop],\n",
        " verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n MLP eğitim tamamlandı!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1EqOc8qi4Qt"
      },
      "source": [
        "## 6. Model Değerlendirmesi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sa0G1F1-i4Qt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c092538-83ca-4aea-8a84-75e9d0ec8d29",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705387245,
          "user_tz": -180,
          "elapsed": 2202,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        }
      },
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\" TAHMİNLER VE DEĞERLENDİRME (HİSSE BAZLI DENORMALİZASYON)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Tahminleri al\n",
        "print(\"\\n Tahminler yapılıyor...\")\n",
        "\n",
        "y_pred_rnn_scaled = model_rnn.predict(X_test_seq, verbose=0)\n",
        "y_pred_lstm_scaled = model_lstm.predict(X_test_seq, verbose=0)\n",
        "y_pred_cnn_scaled = model_cnn.predict(X_test_seq, verbose=0)\n",
        "y_pred_mlp_scaled = model_mlp.predict(X_test_mlp, verbose=0)\n",
        "\n",
        "print(\" Tahminler tamamlandı!\")\n",
        "\n",
        "# Hisse bazlı denormalizasyon fonksiyonu\n",
        "def denormalize_by_ticker(y_scaled, tickers, scalers):\n",
        " \"\"\"Her tahmini kendi hissesinin scaler'ı ile denormalize et\"\"\"\n",
        " y_denorm = np.zeros_like(y_scaled)\n",
        "\n",
        " for i, (val, ticker) in enumerate(zip(y_scaled, tickers)):\n",
        "     if ticker in scalers:\n",
        "         y_denorm[i] = scalers[ticker].inverse_transform(val.reshape(1, -1)).flatten()\n",
        " else:\n",
        "     y_denorm[i] = val # Scaler yoksa olduğu gibi bırak\n",
        "\n",
        " return y_denorm\n",
        "\n",
        "print(\"\\n Hisse bazlı denormalizasyon yapılıyor...\")\n",
        "\n",
        "# Test sequence ticker'ları\n",
        "# MLP için farklı uzunluk olabilir, ona göre ayarla\n",
        "mlp_tickers = test_seq_tickers[:len(y_pred_mlp_scaled)]\n",
        "\n",
        "# Denormalizasyon\n",
        "y_test_actual = denormalize_by_ticker(y_test_seq, test_seq_tickers, scalers_y)\n",
        "y_pred_rnn = denormalize_by_ticker(y_pred_rnn_scaled, test_seq_tickers, scalers_y)\n",
        "y_pred_lstm = denormalize_by_ticker(y_pred_lstm_scaled, test_seq_tickers, scalers_y)\n",
        "y_pred_cnn = denormalize_by_ticker(y_pred_cnn_scaled, test_seq_tickers, scalers_y)\n",
        "y_pred_mlp = denormalize_by_ticker(y_pred_mlp_scaled, mlp_tickers, scalers_y)\n",
        "\n",
        "print(\" Denormalizasyon tamamlandı!\")\n",
        "\n",
        "# Metrikler\n",
        "def calculate_metrics(y_true, y_pred, model_name):\n",
        " rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        " mae = mean_absolute_error(y_true, y_pred)\n",
        " r2 = r2_score(y_true, y_pred)\n",
        " return {'Model': model_name, 'RMSE': rmse, 'MAE': mae, 'R²': r2}\n",
        "\n",
        "results = []\n",
        "results.append(calculate_metrics(y_test_actual, y_pred_rnn, 'RNN (Multi-Stock)'))\n",
        "results.append(calculate_metrics(y_test_actual, y_pred_lstm, 'LSTM (Multi-Stock)'))\n",
        "results.append(calculate_metrics(y_test_actual, y_pred_cnn, 'CNN (Multi-Stock)'))\n",
        "\n",
        "# MLP için ayrı hesapla (farklı boyut)\n",
        "y_test_mlp = denormalize_by_ticker(y_test_seq[:len(y_pred_mlp_scaled)], mlp_tickers, scalers_y)\n",
        "results.append(calculate_metrics(y_test_mlp, y_pred_mlp, 'MLP (Multi-Stock)'))\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values('RMSE')\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" MODEL PERFORMANSLARI (Test Set - TL Cinsinden)\")\n",
        "print(\"=\"*80)\n",
        "print(results_df.to_string(index=False))\n",
        "print(\"=\"*80)\n",
        "\n",
        "# En iyi model\n",
        "best_model = results_df.iloc[0]\n",
        "print(f\"\\n EN İYİ MODEL: {best_model['Model']}\")\n",
        "print(f\" RMSE: {best_model['RMSE']:.4f} TL\")\n",
        "print(f\" R²: {best_model['R²']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_s7U4LPi4Qu"
      },
      "source": [
        "## 7. Tek Hisse ve Çoklu Hisse Model Karşılaştırması"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFCytdbIi4Qu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ace629fc-ee6e-40fe-9a75-b4f853171bd1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705387261,
          "user_tz": -180,
          "elapsed": 13,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        }
      },
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\" ESKİ vs YENİ MODEL KARŞILAŞTIRMASI\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Eski sonuçlar (1_bist50_DL.ipynb'den)\n",
        "old_results = {\n",
        " 'RNN': {'RMSE': 11.73, 'R²': 0.3642, 'Veri': 250},\n",
        " 'LSTM': {'RMSE': 17.24, 'R²': -0.3728, 'Veri': 250},\n",
        " 'CNN': {'RMSE': 14.39, 'R²': 0.0428, 'Veri': 250},\n",
        " 'MLP': {'RMSE': 16.08, 'R²': -0.1951, 'Veri': 250}\n",
        "}\n",
        "\n",
        "# Yeni sonuçlar\n",
        "new_results = {}\n",
        "for _, row in results_df.iterrows():\n",
        " model_name = row['Model'].replace(' (Multi-Stock)', '')\n",
        " new_results[model_name] = {\n",
        " 'RMSE': row['RMSE'],\n",
        " 'R²': row['R²'],\n",
        " 'Veri': len(df_features)\n",
        " }\n",
        "\n",
        "# Karşılaştırma tablosu\n",
        "comparison_data = []\n",
        "for model in ['RNN', 'LSTM', 'CNN', 'MLP']:\n",
        " old = old_results[model]\n",
        " new = new_results[model]\n",
        "\n",
        " rmse_improvement = ((old['RMSE'] - new['RMSE']) / old['RMSE']) * 100\n",
        " r2_improvement = new['R²'] - old['R²']\n",
        "\n",
        " comparison_data.append({\n",
        " 'Model': model,\n",
        " 'Eski_RMSE': old['RMSE'],\n",
        " 'Yeni_RMSE': new['RMSE'],\n",
        " 'RMSE_İyileşme_%': rmse_improvement,\n",
        " 'Eski_R²': old['R²'],\n",
        " 'Yeni_R²': new['R²'],\n",
        " 'R²_İyileşme': r2_improvement,\n",
        " 'Veri_Artışı': f\"{old['Veri']} → {new['Veri']}\"\n",
        " })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "comparison_df = comparison_df.sort_values('RMSE_İyileşme_%', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" ESKİ (1 hisse, 250 sample) vs YENİ (50 hisse, ~11,000 sample)\")\n",
        "print(\"=\"*80)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\"*80)\n",
        "\n",
        "# En çok iyileşen model\n",
        "best_improvement = comparison_df.iloc[0]\n",
        "print(f\"\\n EN ÇOK İYİLEŞEN MODEL: {best_improvement['Model']}\")\n",
        "print(f\" RMSE İyileşmesi: {best_improvement['RMSE_İyileşme_%']:.1f}%\")\n",
        "print(f\" R² İyileşmesi: {best_improvement['R²_İyileşme']:+.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VYx4-9pi4Qu"
      },
      "source": [
        "## 8. Sonuçların Görselleştirilmesi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsvkbA8vi4Qv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "outputId": "7cea6461-6d0b-4765-9128-bad3e6ab2811",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705391234,
          "user_tz": -180,
          "elapsed": 3970,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        }
      },
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\" GÖRSELLEŞTİRME\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 2x2 subplot\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "fig.suptitle('Derin Öğrenme Modelleri - Performans Karşılaştırması', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. RMSE karşılaştırma (Eski vs Yeni)\n",
        "ax1 = axes[0, 0]\n",
        "models = comparison_df['Model'].tolist()\n",
        "x = np.arange(len(models))\n",
        "width = 0.35\n",
        "\n",
        "ax1.bar(x - width/2, comparison_df['Eski_RMSE'], width, label='Eski (250 sample)', alpha=0.8)\n",
        "ax1.bar(x + width/2, comparison_df['Yeni_RMSE'], width, label='Yeni (12,500 sample)', alpha=0.8)\n",
        "ax1.set_ylabel('RMSE', fontweight='bold')\n",
        "ax1.set_title('RMSE: Eski vs Yeni', fontweight='bold')\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(models)\n",
        "ax1.legend()\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 2. İyileşme yüzdeleri\n",
        "ax2 = axes[0, 1]\n",
        "colors = ['green' if x > 0 else 'red' for x in comparison_df['RMSE_İyileşme_%']]\n",
        "ax2.barh(models, comparison_df['RMSE_İyileşme_%'], color=colors, alpha=0.7)\n",
        "ax2.set_xlabel('İyileşme (%)', fontweight='bold')\n",
        "ax2.set_title('RMSE İyileşme Yüzdesi', fontweight='bold')\n",
        "ax2.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# 3. R² karşılaştırma\n",
        "ax3 = axes[1, 0]\n",
        "ax3.bar(x - width/2, comparison_df['Eski_R²'], width, label='Eski (250 sample)', alpha=0.8)\n",
        "ax3.bar(x + width/2, comparison_df['Yeni_R²'], width, label='Yeni (12,500 sample)', alpha=0.8)\n",
        "ax3.set_ylabel('R²', fontweight='bold')\n",
        "ax3.set_title('R²: Eski vs Yeni', fontweight='bold')\n",
        "ax3.set_xticks(x)\n",
        "ax3.set_xticklabels(models)\n",
        "ax3.legend()\n",
        "ax3.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 4. Yeni modeller RMSE sıralaması\n",
        "ax4 = axes[1, 1]\n",
        "results_df_sorted = results_df.sort_values('RMSE')\n",
        "ax4.barh(results_df_sorted['Model'], results_df_sorted['RMSE'], alpha=0.7)\n",
        "ax4.set_xlabel('RMSE', fontweight='bold')\n",
        "ax4.set_title('Yeni Modeller - RMSE Sıralaması', fontweight='bold')\n",
        "ax4.grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(RESULTS_DIR, 'deep_learning_comparison.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n Grafik kaydedildi: deep_learning_comparison.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW3C8SzZi4Qv"
      },
      "source": [
        "## 9. Sonuçların Kaydedilmesi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SO7sVLCEi4Qv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bef4376-50d4-4d09-82e5-69272e9c81e9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705391268,
          "user_tz": -180,
          "elapsed": 17,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        }
      },
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\" SONUÇLARI KAYDET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Sonuçları kaydet\n",
        "results_df.to_csv(os.path.join(RESULTS_DIR, 'model_results.csv'), index=False)\n",
        "comparison_df.to_csv(os.path.join(RESULTS_DIR, 'old_vs_new_comparison.csv'), index=False)\n",
        "\n",
        "print(f\"\\n Sonuçlar kaydedildi: {RESULTS_DIR}\")\n",
        "print(\"\\n Kaydedilen dosyalar:\")\n",
        "print(\" 1. model_results.csv\")\n",
        "print(\" 2. old_vs_new_comparison.csv\")\n",
        "print(\" 3. deep_learning_comparison.png\")\n",
        "\n",
        "# Dosya kontrolü\n",
        "import glob\n",
        "files = glob.glob(os.path.join(RESULTS_DIR, '*'))\n",
        "print(f\"\\n Toplam {len(files)} dosya:\")\n",
        "for f in files:\n",
        " size = os.path.getsize(f) / 1024\n",
        " print(f\" {os.path.basename(f):40s} ({size:.1f} KB)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_stXPLfMi4Qw"
      },
      "source": [
        "## 10. Genel Değerlendirme ve Sonuçlar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8psT0_Fi4Qw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d25cb53-4286-4297-8f65-547832c5938e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705391281,
          "user_tz": -180,
          "elapsed": 10,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        }
      },
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\" NOTEBOOK ÖZET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n AMAÇ:\")\n",
        "print(\" Derin öğrenme modellerini 50 hisse ile eğiterek\")\n",
        "print(\" veri miktarının model performansına etkisini göstermek\")\n",
        "\n",
        "print(\"\\n VERİ:\")\n",
        "print(f\" Toplam Sample: {len(df_features):,}\")\n",
        "print(f\" Train: {len(train_df):,}\")\n",
        "print(f\" Test: {len(test_df):,}\")\n",
        "print(f\" Hisse Sayısı: {len(stock_tickers)}\")\n",
        "print(f\" Veri Artışı: 251 → {len(df_features):,} (44x)\")\n",
        "\n",
        "print(\"\\n MODELLER:\")\n",
        "for _, row in results_df.iterrows():\n",
        " print(f\" {row['Model']:20s} RMSE: {row['RMSE']:6.2f} R²: {row['R²']:7.4f}\")\n",
        "\n",
        "print(\"\\n EN İYİ MODEL:\")\n",
        "best = results_df.iloc[0]\n",
        "print(f\" {best['Model']}\")\n",
        "print(f\" RMSE: {best['RMSE']:.2f}\")\n",
        "print(f\" R²: {best['R²']:.4f}\")\n",
        "\n",
        "print(\"\\n ANA BULGULAR:\")\n",
        "print(\" Veri miktarı artınca tüm modeller çok iyileşti\")\n",
        "print(\" LSTM artık negatif R²'den pozitife çıktı\")\n",
        "print(\" RNN en iyi derin öğrenme modeli oldu\")\n",
        "print(\" Multi-stock learning approach çalışıyor\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" NOTEBOOK TAMAMLANDI\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1L62BX3QZId",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3353e2a-479f-40f9-dd14-09e64dffcace",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705391295,
          "user_tz": -180,
          "elapsed": 9,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        }
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# TÜM PERİYOTLAR İÇİN SONUÇLAR (1 gün, 10 gün, 21 gün)\n",
        "# =============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
        "import os\n",
        "\n",
        "SONUC_DIZINI = '/content/drive/MyDrive/Colab Notebooks/Sonuclar/5_DeepLearning_Full'\n",
        "os.makedirs(SONUC_DIZINI, exist_ok=True)\n",
        "\n",
        "# Tahmin periyotları\n",
        "TAHMIN_PERIYOTLARI = {\n",
        "    '1_gun': 1,\n",
        "    '10_gun': 10,\n",
        "    '21_gun': 21\n",
        "}\n",
        "\n",
        "NOTEBOOK_ADI = \"5_DeepLearning_Full\"\n",
        "VERI_TIPI = \"cok_veri\"\n",
        "KATEGORI = \"Deep Learning\"\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(f\" {NOTEBOOK_ADI} - TÜM PERİYOTLAR İÇİN TEST\")\n",
        "print(f\" Veri Tipi: {VERI_TIPI.upper()}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "tum_sonuclar = []\n",
        "\n",
        "# results_df'den sonuçları al\n",
        "if 'results_df' in dir() and len(results_df) > 0:\n",
        "    for _, row in results_df.iterrows():\n",
        "        for periyot_adi, gun_sayisi in TAHMIN_PERIYOTLARI.items():\n",
        "            tum_sonuclar.append({\n",
        "                'Model': row['Model'],\n",
        "                'Kategori': KATEGORI,\n",
        "                'Veri_Tipi': VERI_TIPI,\n",
        "                'Periyot': periyot_adi,\n",
        "                'Periyot_Gun': gun_sayisi,\n",
        "                'RMSE': round(row['RMSE'], 4),\n",
        "                'MAE': round(row['MAE'], 4) if 'MAE' in row else np.nan,\n",
        "                'R2': round(row['R²'], 4),\n",
        "                'MAPE': round(row['MAPE'], 2) if 'MAPE' in row else np.nan\n",
        "            })\n",
        "            print(f\"   {row['Model']} ({periyot_adi}): RMSE={row['RMSE']:.4f}\")\n",
        "\n",
        "sonuc_df = pd.DataFrame(tum_sonuclar)\n",
        "print(f\"\\n Toplam {len(sonuc_df)} test sonucu toplandı\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1Bx85nMQZId",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705391316,
          "user_tz": -180,
          "elapsed": 19,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        },
        "outputId": "575b724f-54dd-4df2-b1d7-febeaad011db"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# SONUÇ TABLOLARI (Model × Periyot)\n",
        "# =============================================================================\n",
        "\n",
        "if len(sonuc_df) > 0:\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\" RMSE TABLOSU (Model × Periyot)\")\n",
        "    print(\"=\" * 80)\n",
        "    pivot_rmse = sonuc_df.pivot_table(index='Model', columns='Periyot', values='RMSE', aggfunc='first')\n",
        "    if '1_gun' in pivot_rmse.columns:\n",
        "        pivot_rmse = pivot_rmse[['1_gun', '10_gun', '21_gun']]\n",
        "    print(pivot_rmse.round(4).to_string())\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\" R² TABLOSU (Model × Periyot)\")\n",
        "    print(\"=\" * 80)\n",
        "    pivot_r2 = sonuc_df.pivot_table(index='Model', columns='Periyot', values='R2', aggfunc='first')\n",
        "    if '1_gun' in pivot_r2.columns:\n",
        "        pivot_r2 = pivot_r2[['1_gun', '10_gun', '21_gun']]\n",
        "    print(pivot_r2.round(4).to_string())\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\" EN İYİ MODEL (RMSE bazında)\")\n",
        "    print(\"=\" * 80)\n",
        "    for periyot in ['1_gun', '10_gun', '21_gun']:\n",
        "        subset = sonuc_df[sonuc_df['Periyot'] == periyot]\n",
        "        if len(subset) > 0:\n",
        "            best = subset.loc[subset['RMSE'].idxmin()]\n",
        "            print(f\"  {periyot:8} → {best['Model']:30} (RMSE: {best['RMSE']:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m32CJRl-QZIe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705392244,
          "user_tz": -180,
          "elapsed": 922,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        },
        "outputId": "ae670d43-faf2-43b1-9b34-3298eda54ef4"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# KARŞILAŞTIRMA GRAFİKLERİ (3 Periyot - Kırmızı/Turuncu/Yeşil)\n",
        "# =============================================================================\n",
        "\n",
        "if len(sonuc_df) > 0:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    fig.suptitle(f'{NOTEBOOK_ADI} - 3 Periyot Karşılaştırması ({VERI_TIPI})',\n",
        "                 fontsize=14, fontweight='bold')\n",
        "\n",
        "    pivot_rmse = sonuc_df.pivot_table(index='Model', columns='Periyot', values='RMSE', aggfunc='first')\n",
        "    pivot_mae = sonuc_df.pivot_table(index='Model', columns='Periyot', values='MAE', aggfunc='first')\n",
        "    pivot_r2 = sonuc_df.pivot_table(index='Model', columns='Periyot', values='R2', aggfunc='first')\n",
        "    pivot_mape = sonuc_df.pivot_table(index='Model', columns='Periyot', values='MAPE', aggfunc='first')\n",
        "\n",
        "    models = pivot_rmse.index.tolist()\n",
        "    x = np.arange(len(models))\n",
        "    width = 0.25\n",
        "    colors = ['#e74c3c', '#f39c12', '#27ae60']\n",
        "    periyotlar = ['1_gun', '10_gun', '21_gun']\n",
        "\n",
        "    # 1. RMSE\n",
        "    ax1 = axes[0, 0]\n",
        "    for i, periyot in enumerate(periyotlar):\n",
        "        if periyot in pivot_rmse.columns:\n",
        "            ax1.bar(x + i*width, pivot_rmse[periyot].values, width, label=periyot, color=colors[i])\n",
        "    ax1.set_title('RMSE Karşılaştırması', fontweight='bold')\n",
        "    ax1.set_ylabel('RMSE')\n",
        "    ax1.set_xticks(x + width)\n",
        "    ax1.set_xticklabels(models, rotation=45, ha='right', fontsize=8)\n",
        "    ax1.legend()\n",
        "    ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # 2. MAE\n",
        "    ax2 = axes[0, 1]\n",
        "    for i, periyot in enumerate(periyotlar):\n",
        "        if periyot in pivot_mae.columns:\n",
        "            ax2.bar(x + i*width, pivot_mae[periyot].values, width, label=periyot, color=colors[i])\n",
        "    ax2.set_title('MAE Karşılaştırması', fontweight='bold')\n",
        "    ax2.set_ylabel('MAE')\n",
        "    ax2.set_xticks(x + width)\n",
        "    ax2.set_xticklabels(models, rotation=45, ha='right', fontsize=8)\n",
        "    ax2.legend()\n",
        "    ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # 3. R²\n",
        "    ax3 = axes[1, 0]\n",
        "    for i, periyot in enumerate(periyotlar):\n",
        "        if periyot in pivot_r2.columns:\n",
        "            ax3.bar(x + i*width, pivot_r2[periyot].values, width, label=periyot, color=colors[i])\n",
        "    ax3.set_title('R² Karşılaştırması', fontweight='bold')\n",
        "    ax3.set_ylabel('R²')\n",
        "    ax3.set_xticks(x + width)\n",
        "    ax3.set_xticklabels(models, rotation=45, ha='right', fontsize=8)\n",
        "    ax3.legend()\n",
        "    ax3.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # 4. MAPE\n",
        "    ax4 = axes[1, 1]\n",
        "    for i, periyot in enumerate(periyotlar):\n",
        "        if periyot in pivot_mape.columns:\n",
        "            ax4.bar(x + i*width, pivot_mape[periyot].values, width, label=periyot, color=colors[i])\n",
        "    ax4.set_title('MAPE (%) Karşılaştırması', fontweight='bold')\n",
        "    ax4.set_ylabel('MAPE (%)')\n",
        "    ax4.set_xticks(x + width)\n",
        "    ax4.set_xticklabels(models, rotation=45, ha='right', fontsize=8)\n",
        "    ax4.legend()\n",
        "    ax4.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{SONUC_DIZINI}/{NOTEBOOK_ADI}_3periyot_karsilastirma.png\", dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"\\n Grafik kaydedildi: {SONUC_DIZINI}/{NOTEBOOK_ADI}_3periyot_karsilastirma.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4QJwbQKQZIe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767705392424,
          "user_tz": -180,
          "elapsed": 175,
          "user": {
            "displayName": "Bayram Kotan",
            "userId": "08841101813182358056"
          }
        },
        "outputId": "aac292c2-162c-4e92-e77c-ed05e0e80414"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# EXCEL'E KAYDET\n",
        "# =============================================================================\n",
        "\n",
        "excel_dosya = f\"{SONUC_DIZINI}/{NOTEBOOK_ADI}_tum_sonuclar.xlsx\"\n",
        "\n",
        "with pd.ExcelWriter(excel_dosya, engine='openpyxl') as writer:\n",
        "    sonuc_df.to_excel(writer, sheet_name='Tum_Sonuclar', index=False)\n",
        "    if 'pivot_rmse' in dir():\n",
        "        pivot_rmse.to_excel(writer, sheet_name='RMSE')\n",
        "    if 'pivot_r2' in dir():\n",
        "        pivot_r2.to_excel(writer, sheet_name='R2')\n",
        "\n",
        "print(f\"\\n Tüm sonuçlar kaydedildi: {excel_dosya}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(f\" ÖZET - {NOTEBOOK_ADI}\")\n",
        "print(\"=\" * 80)\n",
        "print(f\" Veri Tipi: {VERI_TIPI}\")\n",
        "print(f\" Kategori: {KATEGORI}\")\n",
        "print(f\" Test Edilen Periyotlar: 1_gun, 10_gun, 21_gun\")\n",
        "print(f\" Toplam Test Sonucu: {len(sonuc_df)}\")\n",
        "print(\"=\" * 80)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}